{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__IPYTHON__' in globals():\n",
    "    from IPython import get_ipython\n",
    "    ipython = get_ipython()\n",
    "    ipython.magic('load_ext autoreload')\n",
    "    ipython.magic('autoreload 2')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Loan_Status\"\n",
    "random_state= 42\n",
    "val_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df[\"Loan_Status\"] = df[\"Loan_Status\"].map({\"Y\":1, \"N\":0})\n",
    "\n",
    "X_train, y_train = (\n",
    "    df.drop(target, axis=1),\n",
    "    df.pop(target),\n",
    ")\n",
    "\n",
    "X_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_feature_bins(X, bins=[0,1], labels=None):\n",
    "    X = pd.cut(X.flatten(), bins, labels=labels)\n",
    "    return np.array(X).reshape(-1, 1)\n",
    "\n",
    "def log(X):\n",
    "    return np.log(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "        ),\n",
    "        [\"Gender\", \"Married\", \"Self_Employed\", \"Credit_History\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OrdinalEncoder(),\n",
    "        ),\n",
    "        [\"Dependents\"],\n",
    "    ),\n",
    "    (\n",
    "        make_pipeline(SimpleImputer(strategy=\"median\"), FunctionTransformer(log)),\n",
    "        [\"LoanAmount\"],\n",
    "    ),\n",
    "    (\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        [\"Loan_Amount_Term\"],\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=1, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 0.0018\n",
      "score_time: 0.0022\n",
      "test_accuracy: 0.8095\n",
      "test_roc_auc: 0.7189\n",
      "test_f1: 0.8769\n"
     ]
    }
   ],
   "source": [
    "# Transform X_train and X_val\n",
    "X_train_features = features.fit_transform(X_train)\n",
    "\n",
    "# Metrics to evaluate the model\n",
    "scoring = (\"accuracy\", \"roc_auc\", \"f1\")\n",
    "\n",
    "# Cross validation\n",
    "scores = cross_validate(\n",
    "    model, X_train_features, y_train, cv=15, scoring=scoring, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Mean value of the metrics\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v.mean():0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make predictions and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features = features.transform(X_test)\n",
    "\n",
    "model.fit(X_train_features, y_train)\n",
    "y_test_pred = model.predict(X_test_features)\n",
    "\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submission['Loan_Status']= y_test_pred\n",
    "submission['Loan_Status'] = submission['Loan_Status'].map({1:\"Y\", 0:\"N\"})\n",
    "submission.to_csv(f\"{model.__class__.__name__}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c684bbac1711ee96eb4ea849084181282891a93248b0592bf8c1982c07408e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('loan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
